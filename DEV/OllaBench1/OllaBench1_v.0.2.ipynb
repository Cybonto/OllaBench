{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "tags": [
     "dev_only"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook OllaBench1_v.0.2.ipynb to script\n",
      "[NbConvertApp] Writing 12110 bytes to ..\\..\\OllaBench1.py\n"
     ]
    }
   ],
   "source": [
    "#### Dev Only Cell ####\n",
    "# Run this cell to export production code to .py file in the parent folder\n",
    "# Make sure to save the notebook first\n",
    "# dev_only cells will not be written to .py\n",
    "import shutil\n",
    "shutil.copyfile('./params.json', '../../params.json')\n",
    "!jupyter nbconvert --to script OllaBench1_v.0.2.ipynb --output OllaBench1 --output-dir='../../' --TagRemovePreprocessor.enabled=True --TagRemovePreprocessor.remove_cell_tags='{\"dev_only\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "ConnectError",
     "evalue": "[WinError 10061] No connection could be made because the target machine actively refused it",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:69\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     68\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m---> 69\u001b[0m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[0;32m     70\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:233\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    232\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m map_httpcore_exceptions():\n\u001b[1;32m--> 233\u001b[0m     resp \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:216\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    215\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_close_connections(closing)\n\u001b[1;32m--> 216\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;66;03m# Return the response. Note that in this case we still have to manage\u001b[39;00m\n\u001b[0;32m    219\u001b[0m \u001b[38;5;66;03m# the point at which the response is closed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection_pool.py:196\u001b[0m, in \u001b[0;36mConnectionPool.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    194\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    195\u001b[0m     \u001b[38;5;66;03m# Send the request on the assigned connection.\u001b[39;00m\n\u001b[1;32m--> 196\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mconnection\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    197\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpool_request\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\n\u001b[0;32m    198\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    199\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m ConnectionNotAvailable:\n\u001b[0;32m    200\u001b[0m     \u001b[38;5;66;03m# In some cases a connection may initially be available to\u001b[39;00m\n\u001b[0;32m    201\u001b[0m     \u001b[38;5;66;03m# handle a request, but then become unavailable.\u001b[39;00m\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;66;03m#\u001b[39;00m\n\u001b[0;32m    203\u001b[0m     \u001b[38;5;66;03m# In this case we clear the connection and try again.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection.py:99\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     98\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connect_failed \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m---> 99\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m exc\n\u001b[0;32m    101\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection\u001b[38;5;241m.\u001b[39mhandle_request(request)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection.py:76\u001b[0m, in \u001b[0;36mHTTPConnection.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_connection \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m---> 76\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_connect\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     78\u001b[0m     ssl_object \u001b[38;5;241m=\u001b[39m stream\u001b[38;5;241m.\u001b[39mget_extra_info(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mssl_object\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_sync\\connection.py:122\u001b[0m, in \u001b[0;36mHTTPConnection._connect\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    121\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m Trace(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mconnect_tcp\u001b[39m\u001b[38;5;124m\"\u001b[39m, logger, request, kwargs) \u001b[38;5;28;01mas\u001b[39;00m trace:\n\u001b[1;32m--> 122\u001b[0m     stream \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_network_backend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mconnect_tcp\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    123\u001b[0m     trace\u001b[38;5;241m.\u001b[39mreturn_value \u001b[38;5;241m=\u001b[39m stream\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_backends\\sync.py:205\u001b[0m, in \u001b[0;36mSyncBackend.connect_tcp\u001b[1;34m(self, host, port, timeout, local_address, socket_options)\u001b[0m\n\u001b[0;32m    200\u001b[0m exc_map: ExceptionMapping \u001b[38;5;241m=\u001b[39m {\n\u001b[0;32m    201\u001b[0m     socket\u001b[38;5;241m.\u001b[39mtimeout: ConnectTimeout,\n\u001b[0;32m    202\u001b[0m     \u001b[38;5;167;01mOSError\u001b[39;00m: ConnectError,\n\u001b[0;32m    203\u001b[0m }\n\u001b[1;32m--> 205\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mexc_map\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    206\u001b[0m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43msocket\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcreate_connection\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    207\u001b[0m \u001b[43m        \u001b[49m\u001b[43maddress\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    208\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    209\u001b[0m \u001b[43m        \u001b[49m\u001b[43msource_address\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msource_address\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    210\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpcore\\_exceptions.py:14\u001b[0m, in \u001b[0;36mmap_exceptions\u001b[1;34m(map)\u001b[0m\n\u001b[0;32m     13\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(exc, from_exc):\n\u001b[1;32m---> 14\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m to_exc(exc) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mConnectError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 70\u001b[0m\n\u001b[0;32m     48\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     49\u001b[0m \u001b[38;5;124;03mif llm_framework==\"openai\":\u001b[39;00m\n\u001b[0;32m     50\u001b[0m \u001b[38;5;124;03m    from openai import OpenAI\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;124;03m    completion_to_prompt=completion_to_prompt)\u001b[39;00m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[0;32m     69\u001b[0m \u001b[38;5;66;03m# Prepare the list of targetted LLM models\u001b[39;00m\n\u001b[1;32m---> 70\u001b[0m llm_list \u001b[38;5;241m=\u001b[39m [d[\u001b[38;5;28mnext\u001b[39m(\u001b[38;5;28miter\u001b[39m(d))] \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[43mollama\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlist\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mmodels\u001b[39m\u001b[38;5;124m'\u001b[39m]] \u001b[38;5;66;03m#get model names from the list of dict returned by Ollama\u001b[39;00m\n\u001b[0;32m     71\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m llm_models\u001b[38;5;241m==\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mall\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m     72\u001b[0m     llm_models\u001b[38;5;241m=\u001b[39mllm_list\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:330\u001b[0m, in \u001b[0;36mClient.list\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    329\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Mapping[\u001b[38;5;28mstr\u001b[39m, Any]:\n\u001b[1;32m--> 330\u001b[0m   \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_request\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mGET\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/api/tags\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241m.\u001b[39mjson()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\ollama\\_client.py:68\u001b[0m, in \u001b[0;36mClient._request\u001b[1;34m(self, method, url, **kwargs)\u001b[0m\n\u001b[0;32m     67\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_request\u001b[39m(\u001b[38;5;28mself\u001b[39m, method: \u001b[38;5;28mstr\u001b[39m, url: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m httpx\u001b[38;5;241m.\u001b[39mResponse:\n\u001b[1;32m---> 68\u001b[0m   response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_client\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     70\u001b[0m   \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m     71\u001b[0m     response\u001b[38;5;241m.\u001b[39mraise_for_status()\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:827\u001b[0m, in \u001b[0;36mClient.request\u001b[1;34m(self, method, url, content, data, files, json, params, headers, cookies, auth, follow_redirects, timeout, extensions)\u001b[0m\n\u001b[0;32m    812\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(message, \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m)\n\u001b[0;32m    814\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mbuild_request(\n\u001b[0;32m    815\u001b[0m     method\u001b[38;5;241m=\u001b[39mmethod,\n\u001b[0;32m    816\u001b[0m     url\u001b[38;5;241m=\u001b[39murl,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    825\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mextensions,\n\u001b[0;32m    826\u001b[0m )\n\u001b[1;32m--> 827\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:914\u001b[0m, in \u001b[0;36mClient.send\u001b[1;34m(self, request, stream, auth, follow_redirects)\u001b[0m\n\u001b[0;32m    906\u001b[0m follow_redirects \u001b[38;5;241m=\u001b[39m (\n\u001b[0;32m    907\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfollow_redirects\n\u001b[0;32m    908\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(follow_redirects, UseClientDefault)\n\u001b[0;32m    909\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m follow_redirects\n\u001b[0;32m    910\u001b[0m )\n\u001b[0;32m    912\u001b[0m auth \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_build_request_auth(request, auth)\n\u001b[1;32m--> 914\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_auth\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    915\u001b[0m \u001b[43m    \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    916\u001b[0m \u001b[43m    \u001b[49m\u001b[43mauth\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mauth\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    917\u001b[0m \u001b[43m    \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    918\u001b[0m \u001b[43m    \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    919\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    920\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    921\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m stream:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:942\u001b[0m, in \u001b[0;36mClient._send_handling_auth\u001b[1;34m(self, request, auth, follow_redirects, history)\u001b[0m\n\u001b[0;32m    939\u001b[0m request \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(auth_flow)\n\u001b[0;32m    941\u001b[0m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;28;01mTrue\u001b[39;00m:\n\u001b[1;32m--> 942\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_handling_redirects\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    943\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    944\u001b[0m \u001b[43m        \u001b[49m\u001b[43mfollow_redirects\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mfollow_redirects\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    945\u001b[0m \u001b[43m        \u001b[49m\u001b[43mhistory\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhistory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    946\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    947\u001b[0m     \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    948\u001b[0m         \u001b[38;5;28;01mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:979\u001b[0m, in \u001b[0;36mClient._send_handling_redirects\u001b[1;34m(self, request, follow_redirects, history)\u001b[0m\n\u001b[0;32m    976\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mrequest\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[0;32m    977\u001b[0m     hook(request)\n\u001b[1;32m--> 979\u001b[0m response \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_send_single_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    980\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m    981\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m hook \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_event_hooks[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mresponse\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_client.py:1015\u001b[0m, in \u001b[0;36mClient._send_single_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m   1010\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1011\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAttempted to send an async request with a sync Client instance.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1012\u001b[0m     )\n\u001b[0;32m   1014\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m request_context(request\u001b[38;5;241m=\u001b[39mrequest):\n\u001b[1;32m-> 1015\u001b[0m     response \u001b[38;5;241m=\u001b[39m \u001b[43mtransport\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1017\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(response\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m   1019\u001b[0m response\u001b[38;5;241m.\u001b[39mrequest \u001b[38;5;241m=\u001b[39m request\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:232\u001b[0m, in \u001b[0;36mHTTPTransport.handle_request\u001b[1;34m(self, request)\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(request\u001b[38;5;241m.\u001b[39mstream, SyncByteStream)\n\u001b[0;32m    220\u001b[0m req \u001b[38;5;241m=\u001b[39m httpcore\u001b[38;5;241m.\u001b[39mRequest(\n\u001b[0;32m    221\u001b[0m     method\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mmethod,\n\u001b[0;32m    222\u001b[0m     url\u001b[38;5;241m=\u001b[39mhttpcore\u001b[38;5;241m.\u001b[39mURL(\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    230\u001b[0m     extensions\u001b[38;5;241m=\u001b[39mrequest\u001b[38;5;241m.\u001b[39mextensions,\n\u001b[0;32m    231\u001b[0m )\n\u001b[1;32m--> 232\u001b[0m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mmap_httpcore_exceptions\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[0;32m    233\u001b[0m \u001b[43m    \u001b[49m\u001b[43mresp\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_pool\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mhandle_request\u001b[49m\u001b[43m(\u001b[49m\u001b[43mreq\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    235\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(resp\u001b[38;5;241m.\u001b[39mstream, typing\u001b[38;5;241m.\u001b[39mIterable)\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\contextlib.py:158\u001b[0m, in \u001b[0;36m_GeneratorContextManager.__exit__\u001b[1;34m(self, typ, value, traceback)\u001b[0m\n\u001b[0;32m    156\u001b[0m     value \u001b[38;5;241m=\u001b[39m typ()\n\u001b[0;32m    157\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m--> 158\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mthrow\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    159\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[0;32m    160\u001b[0m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[0;32m    161\u001b[0m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[0;32m    162\u001b[0m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n\u001b[0;32m    163\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m exc \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m value\n",
      "File \u001b[1;32mc:\\Users\\Administrator\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\httpx\\_transports\\default.py:86\u001b[0m, in \u001b[0;36mmap_httpcore_exceptions\u001b[1;34m()\u001b[0m\n\u001b[0;32m     83\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m\n\u001b[0;32m     85\u001b[0m message \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mstr\u001b[39m(exc)\n\u001b[1;32m---> 86\u001b[0m \u001b[38;5;28;01mraise\u001b[39;00m mapped_exc(message) \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mexc\u001b[39;00m\n",
      "\u001b[1;31mConnectError\u001b[0m: [WinError 10061] No connection could be made because the target machine actively refused it"
     ]
    }
   ],
   "source": [
    "# OllaBench1 v.0.2\n",
    "# IMPORTS\n",
    "\n",
    "## Import Python Libraries\n",
    "import os\n",
    "import doctest\n",
    "import datetime\n",
    "from datetime import datetime\n",
    "import time\n",
    "import random\n",
    "import contextlib\n",
    "\n",
    "import itertools\n",
    "import copy\n",
    "import networkx as nx\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import csv\n",
    "import json\n",
    "\n",
    "import ollama\n",
    "import nltk\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "\n",
    "params_path=\"params.json\"\n",
    "params={}\n",
    "# Read the parameters from the JSON file\n",
    "try:\n",
    "    with open(params_path, 'r') as file:\n",
    "        params = json.load(file)   \n",
    "except FileNotFoundError:\n",
    "    print(f\"The file {params_path} was not found.\")\n",
    "except json.JSONDecodeError:\n",
    "    print(f\"Error decoding JSON from the file {params_path}.\")\n",
    "# Initialize variables\n",
    "llm_framework = params[\"llm_framework\"]\n",
    "llm_endpoints = params[\"llm_endpoints\"]\n",
    "llm_models = params[\"llm_models\"]\n",
    "llm_leaderboard = params[\"llm_leaderboard\"]\n",
    "tries = params[\"bench_tries\"]\n",
    "QA_inpath = params[\"QA_inpath\"] \n",
    "\n",
    "if llm_framework==\"ollama\": # only support Ollama as the eval target framework at the moment\n",
    "    from ollama import Client\n",
    "    client = Client(host=llm_endpoints)\n",
    "\n",
    "'''\n",
    "if llm_framework==\"openai\":\n",
    "    from openai import OpenAI\n",
    "    client = OpenAI(\n",
    "        # This is the default and can be omitted\n",
    "        api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    "    )\n",
    "if llm_framework==\"llama_index\":\n",
    "    from llama_index.llms import LocalTensorRTLLM\n",
    "    def completion_to_prompt(completion: str) -> str:\n",
    "        \"\"\"\n",
    "        Given a completion, return the prompt using llama2 format.\n",
    "        \"\"\"\n",
    "        return f\"<s> [INST] {completion} [/INST] \"\n",
    "    llm = LocalTensorRTLLM(\n",
    "    model_path=\"./model\",\n",
    "    engine_name=\"llama_float16_tp1_rank0.engine\",\n",
    "    tokenizer_dir=\"meta-llama/Llama-2-13b-chat\",\n",
    "    completion_to_prompt=completion_to_prompt)\n",
    "'''\n",
    "\n",
    "# Prepare the list of targetted LLM models\n",
    "llm_list = [d[next(iter(d))] for d in ollama.list()['models']] #get model names from the list of dict returned by Ollama\n",
    "if llm_models==\"all\":\n",
    "    llm_models=llm_list\n",
    "else:\n",
    "    llm_names_bak=llm_models.copy()\n",
    "    llm_models[:] = [item for item in llm_models if item in llm_list] #remove model names that are not installed\n",
    "    print(\"The following model(s) does not exist in Ollama: \"+str([item for item in llm_names_bak if item not in llm_models]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# FUNCTIONS\n",
    "\n",
    "def write_df_to_csv(df, csv_file):\n",
    "    # If the CSV file already exists, append to it, otherwise create a new file\n",
    "    mode = 'a' if os.path.exists(csv_file) else 'w'\n",
    "\n",
    "    # Write the DataFrame to CSV\n",
    "    df.to_csv(csv_file, mode=mode, index=False)\n",
    "    \n",
    "def test_model(tries,a_model):\n",
    "    \"\"\"\n",
    "    A function to check for bad LLM models.\n",
    "    \n",
    "    Parameters:\n",
    "    tries: the number of failed attempts before reporting\n",
    "    llm_models: a list of targeted LLM models\n",
    "    \n",
    "    Returns:\n",
    "    True if the model is good\n",
    "    \"\"\"\n",
    "    print(f\"Test loading of {a_model}\")\n",
    "    while tries>0:\n",
    "        try:\n",
    "            response = get_response(llm_framework,a_model,'just say yes')\n",
    "            return True\n",
    "        except Exception as e:\n",
    "            tries-=1\n",
    "            response = str(e) #\"error\" wil be in response\n",
    "    if \"error\" in response:\n",
    "        print(f\"The model {a_model} is bad.\")\n",
    "    return False \n",
    "\n",
    "def check_answer (reference, answer):\n",
    "    \"\"\"\n",
    "    Check if the correct answer (reference) is within the first two sentences of a model's answer.\n",
    "    \n",
    "    Parameters:\n",
    "    reference : the reference answer\n",
    "    answer : the model's answer\n",
    "    \n",
    "    Returns:\n",
    "    True or False\n",
    "    \"\"\"\n",
    "    norm_ref1 = str(reference).lower()\n",
    "    norm_ref2 = norm_ref1.split(\" - \")[0]\n",
    "    norm_ref3 = norm_ref1.split(\" - \")[1]\n",
    "    norm_ref4 = norm_ref2.replace(\"option \",\"\")\n",
    "    ans_keys = (norm_ref1, norm_ref2, norm_ref3, norm_ref4)\n",
    "    norm_answer = str(answer).lower()\n",
    "\n",
    "    # Tokenize string2 into sentences\n",
    "    sentences = sent_tokenize(norm_answer)\n",
    "\n",
    "    # Combine the first two sentences into one string\n",
    "    first_two_sentences = ' '.join(sentences[:2])\n",
    "\n",
    "    # Check if string1 is in the combined first two sentences\n",
    "    if any(ans_key in first_two_sentences for ans_key in ans_keys):\n",
    "        return True\n",
    "    else:\n",
    "        return False\n",
    "\n",
    "def get_response(llm_framework,a_model,a_prompt):\n",
    "    if llm_framework ==\"ollama\":\n",
    "        result = ollama.generate(model=a_model, prompt= a_prompt, stream=False)\n",
    "        while \"eval_duration\" not in result:\n",
    "            time.sleep(1)\n",
    "    return result\n",
    "\n",
    "def grade_model(a_model,input_df):\n",
    "    \"\"\"\n",
    "    A function to grade an LLM model's responses\n",
    "    \n",
    "    Parameters:\n",
    "    a_model : the target LLM model\n",
    "    input_df : input dataframe that is consistent with OllaGen1 output format\n",
    "    \n",
    "    Returns:\n",
    "    Results_df : a result df with input_df columns and additional columns of\n",
    "    'Model','Total Duration','Eval Counts','Model Response','Score','Notes'\n",
    "    \"\"\"\n",
    "    results=[]\n",
    "\n",
    "    print(f\"Grading {a_model}\")\n",
    "    # load the model in Ollama\n",
    "    get_response(\"ollama\",a_model,'just say yes')\n",
    "\n",
    "    turn = 0\n",
    "    for index, row in input_df.iterrows():\n",
    "        while turn != index:\n",
    "            time.sleep(10)\n",
    "\n",
    "        score=0\n",
    "        context = f\"\"\"\n",
    "            Here are the intelligence about {row[\"P1_name\"]} with comments from trusted experts and/or {row[\"P1_name\"]}'s recorded statement(s).\n",
    "            {row[\"P1_profile\"]}\n",
    "            Here are the intelligence about {row[\"P2_name\"]} with comments from trusted experts and/or {row[\"P2_name\"]}'s recorded statement(s).\n",
    "            {row[\"P2_profile\"]}\n",
    "\n",
    "            \"\"\"\n",
    "        #print(context)\n",
    "        WCP_Question = row[\"WCP_Question\"]\n",
    "        WCP_Answer = row[\"WCP_Answer\"]\n",
    "        WCP_score = 0\n",
    "        WHO_Question = row[\"WHO_Question\"]\n",
    "        WHO_Answer = row[\"WHO_Answer\"]\n",
    "        WHO_score = 0\n",
    "        TeamRisk_Question = row[\"TeamRisk_Question\"]\n",
    "        TeamRisk_Answer = row[\"TeamRisk_Answer\"]\n",
    "        TeamRisk_score = 0\n",
    "        TargetFactor_Question = row[\"TargetFactor_Question\"]\n",
    "        TargetFactor_Answer = row[\"TargetFactor_Answer\"]\n",
    "        TargetFactor_score = 0\n",
    "\n",
    "        WCP_response = get_response(\"ollama\",a_model,str(context+WCP_Question))\n",
    "        while \"eval_duration\" not in WCP_response:\n",
    "            time.sleep(1)\n",
    "        if check_answer(WCP_Answer,WCP_response['response']):\n",
    "            WCP_score = 1\n",
    "        \n",
    "        if \"eval_duration\" in WCP_response:\n",
    "            WHO_response = get_response(\"ollama\",a_model,str(context+WHO_Question))\n",
    "            while \"eval_duration\" not in WHO_response:\n",
    "                time.sleep(1)\n",
    "            if check_answer(WHO_Answer,WHO_response['response']):\n",
    "                WHO_score = 1\n",
    "            if \"eval_duration\" in WHO_response:\n",
    "                TeamRisk_response = get_response(\"ollama\",a_model,str(context+TeamRisk_Question))\n",
    "                while \"eval_duration\" not in TeamRisk_response:\n",
    "                    time.sleep(1)\n",
    "                if check_answer(TeamRisk_Answer,TeamRisk_response['response']):\n",
    "                    TeamRisk_score = 1\n",
    "                if \"eval_duration\" in TeamRisk_response:\n",
    "                    TargetFactor_response = get_response(\"ollama\",a_model,str(context+TargetFactor_Question))\n",
    "                    while \"eval_duration\" not in TargetFactor_response:\n",
    "                        time.sleep(1)\n",
    "                    if check_answer(TargetFactor_Answer,TargetFactor_response['response']):\n",
    "                        TargetFactor_score = 1\n",
    "                    if \"eval_duration\" in TargetFactor_response:\n",
    "                        score = WCP_score+WHO_score+TeamRisk_score+TargetFactor_score\n",
    "\n",
    "                        results.append([row['ID'], a_model, str(context), WCP_Question, WCP_Answer,\n",
    "                                        WCP_response['total_duration'],WCP_response['eval_count'], str(WCP_response['response']),WCP_score,\n",
    "                                        WHO_Question, WHO_Answer,\n",
    "                                        WHO_response['total_duration'],WHO_response['eval_count'], str(WHO_response['response']),WHO_score,\n",
    "                                        TeamRisk_Question, TeamRisk_Answer,\n",
    "                                        TeamRisk_response['total_duration'],TeamRisk_response['eval_count'], str(TeamRisk_response['response']),TeamRisk_score,\n",
    "                                        TargetFactor_Question, TargetFactor_Answer,\n",
    "                                        TargetFactor_response['total_duration'],TargetFactor_response['eval_count'], str(TargetFactor_response['response']),TargetFactor_score,\n",
    "                                        score\n",
    "                                        ])\n",
    "                        turn += 1\n",
    "        if index%50==0:\n",
    "            print(\".\", end =\" \", flush=True)\n",
    "        \n",
    "    results_df = pd.DataFrame(results,columns=['ID', 'Model', 'Context', 'WCP_Question', 'WCP_Correct_Answer',\n",
    "                                                    'WCP_TotalDuration','WCP_EvalCounts','WCP_Response','WCP_score',\n",
    "                                                    'WHO_Question', 'WHO_Correct_Answer',\n",
    "                                                    'WHO_TotalDuration','WHO_EvalCounts','WHO_Response','WHO_score',\n",
    "                                                    'TeamRisk_Question', 'TeamRisk_Correct_Answer',\n",
    "                                                    'TeamRisk_TotalDuration','TeamRisk_EvalCounts','TeamRisk_Response','TeamRisk_score',\n",
    "                                                    'TargetFactor_Question', 'TargetFactor_Correct_Answer',\n",
    "                                                    'TargetFactor_TotalDuration','TargetFactor_EvalCounts','TargetFactor_Response','TargetFactor_score',\n",
    "                                                    'Total score'\n",
    "                                                    ])\n",
    "    print(\" \")\n",
    "    return results_df\n",
    "\n",
    "def df_2_chunks (a_df,chunk_size):\n",
    "    \"\"\"\n",
    "    Function description.\n",
    "    \n",
    "    Parameters:\n",
    "    param : param description\n",
    "    \n",
    "    Returns:\n",
    "    value : value description\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Calculate the total number of chunks to be created\n",
    "        num_chunks = len(a_df) // chunk_size + (1 if len(a_df) % chunk_size else 0)\n",
    "        chunks=[]\n",
    "        for i in range(num_chunks):\n",
    "            # Slice the DataFrame to create a chunk\n",
    "            start_row = i * chunk_size\n",
    "            end_row = start_row + chunk_size\n",
    "            chunk = a_df[start_row:end_row]\n",
    "    \n",
    "            # Append the chunk to the list of chunks\n",
    "            chunks.append(chunk)\n",
    "        return chunks\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\"\n",
    "        \n",
    "def function_template ():\n",
    "    \"\"\"\n",
    "    Function description.\n",
    "    \n",
    "    Parameters:\n",
    "    param : param description\n",
    "    \n",
    "    Returns:\n",
    "    value : value description\n",
    "    \"\"\"\n",
    "    try:\n",
    "        return\n",
    "        # function code here\n",
    "    except Exception as e:\n",
    "        return f\"An error occurred: {str(e)}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loading of llama2:7b\n",
      "Grading llama2:7b\n",
      ".  \n",
      "Graded results were saved to llama2-7b_2024-04-02_14-41_QA_Results.csv\n",
      "Test loading of orca2:7b\n"
     ]
    }
   ],
   "source": [
    "## MAIN\n",
    "\n",
    "# Load QA datasets\n",
    "QA_df = pd.read_csv(QA_inpath,header=0)\n",
    "# Split to chunks\n",
    "chunk_size = 500\n",
    "QA_df_chunks = df_2_chunks(QA_df,chunk_size)\n",
    "greenlight = True\n",
    "greenlight2 = True\n",
    "\n",
    "# Get Results\n",
    "for a_model in llm_models:\n",
    "    while not greenlight:\n",
    "        time.sleep(10)\n",
    "    greenlight=False # turn off greenlight here, pay attn to when it will be turned on again!\n",
    "    test_passed = test_model(tries,a_model)\n",
    "    if test_passed:\n",
    "        for index,QA_df_chunk in enumerate(QA_df_chunks):\n",
    "            while not greenlight2:\n",
    "                time.sleep(60)\n",
    "            greenlight2=False # turn off greenlight2 here, pay attn to when it will be turned on again!\n",
    "            print(f\"Load chunk {index}\")\n",
    "            QA_outpath = a_model.replace(\":\",\"-\")+\"_chunk\"+str(index)+\"_\"+datetime.now().strftime(\"%Y-%m-%d_%H-%M\")+\"_QA_Results.csv\"\n",
    "            if len(QA_df)>0:\n",
    "                QA_result_df = grade_model(a_model,QA_df_chunk)\n",
    "                if len(QA_result_df)>0:\n",
    "                    write_df_to_csv(QA_result_df,QA_outpath)\n",
    "                    print(f\"Graded results were saved to {QA_outpath}\")\n",
    "                    greenlight2 = True\n",
    "                else:\n",
    "                    print(f\"Result is empty. Nothing was saved to {QA_outpath}\")\n",
    "                    greenlight2 = True\n",
    "            else:\n",
    "                print(\"Input dataframe is empty. Program exiting.\")\n",
    "                greenlight2 = True\n",
    "        greenlight=True\n",
    "    else:\n",
    "        print(f\"There are issues with loading {a_model}. Skip the grading of this model.\")\n",
    "        print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "tags": [
     "dev_only"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Index(['WCP_score', 'WHO_score', 'TeamRisk_score', 'TargetFactor_score'], dtype='object')\n",
      "(10000, 4)\n"
     ]
    }
   ],
   "source": [
    "# Dev cell\n",
    "import os\n",
    "from io import StringIO\n",
    "import asyncio\n",
    "import aiofiles\n",
    "import pandas as pd\n",
    "import semopy as sem\n",
    "import graphviz\n",
    "\n",
    "columns_of_interest = ['WCP_score','WHO_score','TeamRisk_score','TargetFactor_score']\n",
    "async def read_csv_async(file_path: str) -> pd.DataFrame:\n",
    "    async with aiofiles.open(file_path, mode='r', encoding='utf-8') as file:\n",
    "        content = await file.read()\n",
    "    df = pd.read_csv(StringIO(content))  # Use StringIO from the io module\n",
    "    return df[columns_of_interest]\n",
    "\n",
    "async def process_model_files(directory: str, model_name: str) -> pd.DataFrame:\n",
    "    tasks = []\n",
    "    for filename in os.listdir(directory):\n",
    "        if filename.startswith(model_name) and filename.endswith(\"_QA_Results.csv\"):\n",
    "            file_path = os.path.join(directory, filename)\n",
    "            tasks.append(read_csv_async(file_path))\n",
    "    dataframes = await asyncio.gather(*tasks)\n",
    "    return pd.concat(dataframes, ignore_index=True)\n",
    "\n",
    "#data_raw = pd.read_csv(\"../../Responses/gemini-1.5-flash-latest_chunk0_2024-05-31_14-33_QA_Results.csv\", header=0)\n",
    "#data = data_raw[columns_of_interest]\n",
    "data = await process_model_files(\"../../Responses/\", \"gemini-1.5\")\n",
    "print(data.columns)\n",
    "print(data.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "tags": [
     "dev_only"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Name of objective: MLW\n",
      "Optimization method: SLSQP\n",
      "Optimization successful.\n",
      "Optimization terminated successfully\n",
      "Objective value: 0.000\n",
      "Number of iterations: 12\n",
      "Params: -0.023 -0.126 0.035 0.093 0.092 0.154 0.153 0.096 0.151 0.110 -0.000 0.131\n"
     ]
    }
   ],
   "source": [
    "# Dev cell\n",
    "m1 = \"\"\"\n",
    "    # measurement model\n",
    "    WCP =~ WCP_score\n",
    "    WHO =~ WHO_score\n",
    "    TR =~ TeamRisk_score\n",
    "    TF =~ TargetFactor_score\n",
    "    # regressions\n",
    "    TR ~ WCP + WHO\n",
    "    TF ~ WCP\n",
    "\"\"\"\n",
    "semM1 = sem.Model(m1)\n",
    "result = semM1.fit(data, obj=\"MLW\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "tags": [
     "dev_only"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model lval op rval  Estimate  Std. Err   z-value   p-value\n",
      "0  gemini   TR  ~  WCP -0.023009  0.740301 -0.031081  0.975205\n",
      "1  gemini   TR  ~  WHO -0.126245  0.013359 -9.449899       0.0\n",
      "2  gemini   TF  ~  WCP  0.034720  1.117149  0.031079  0.975207\n"
     ]
    }
   ],
   "source": [
    "# Dev cell\n",
    "inspect_result = semM1.inspect()\n",
    "df_inspect = pd.DataFrame(inspect_result).head(3)\n",
    "df_inspect.insert(0,\"model\",\"gemini\")\n",
    "print(df_inspect)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "tags": [
     "dev_only"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Fisher Information Matrix is not PD.Moore-Penrose inverse will be used instead of Cholesky decomposition. See 10.1109/TSP.2012.2208105.\n"
     ]
    }
   ],
   "source": [
    "# Dev cell\n",
    "g = sem.semplot(semM1,'result.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "tags": [
     "dev_only"
    ]
   },
   "outputs": [],
   "source": [
    "# Dev cell\n",
    "g = sem.semplot(m1,'sem_model.png')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "tags": [
     "dev_only"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    model lval op rval  Estimate  Std. Err   z-value   p-value\n",
      "0  gemini   TR  ~  WCP -0.023009  0.740301 -0.031081  0.975205\n"
     ]
    }
   ],
   "source": [
    "# Dev cell\n",
    "pairs_to_filter = [('TR','WCP')]\n",
    "filtered_sem_results = df_inspect[df_inspect.apply(lambda row: (row['lval'], row['rval']) in pairs_to_filter, axis=1)]\n",
    "print (filtered_sem_results)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
