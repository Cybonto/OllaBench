{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": [
     "dev_only"
    ]
   },
   "outputs": [],
   "source": [
    "#### Dev Only Cell ####\n",
    "# Run this cell to export production code to .py file in the specified folder\n",
    "# dev_only cells will not be written to .py\n",
    "import shutil\n",
    "shutil.copyfile('./Cybonto-Gen1-PromptSeeds.csv', '../../OllaGen-1/Cybonto-Gen1-PromptSeeds.csv')\n",
    "!jupyter nbconvert --to script OllaGen0_v.0.2.ipynb --output OllaGen0 --output-dir='../../OllaGen-1' --TagRemovePreprocessor.enabled=True --TagRemovePreprocessor.remove_cell_tags='{\"dev_only\"}'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import datetime\n",
    "import time\n",
    "import csv\n",
    "import pandas as pd\n",
    "import shutil\n",
    "\n",
    "llm_framework=\"ollama\"\n",
    "\n",
    "from ollama import Client\n",
    "llm_endpoints = os.environ.get(\"OLLAMA_ENDPOINT\") # specify endpoint url:port here if you don't have OLLAMA_ENDPOINT set\n",
    "ollama_client = Client(host=llm_endpoints)\n",
    "    \n",
    "from openai import OpenAI\n",
    "openai_client = OpenAI(\n",
    "    # This is the default and can be omitted\n",
    "    api_key=os.environ.get(\"OPENAI_API_KEY\"),\n",
    ")\n",
    "\n",
    "construct_list = [\n",
    "    'Affect',\n",
    "    'Attitude',\n",
    "    'Belief',\n",
    "    'Benefits',\n",
    "    'Commitment',\n",
    "    'Control',\n",
    "    'Costs',\n",
    "    'Goal',\n",
    "    'Group norms',\n",
    "    'Intent',\n",
    "    'Knowledge',\n",
    "    'Moral',\n",
    "    'Motivation',\n",
    "    'Norms',\n",
    "    'Response Efficacy',\n",
    "    'Self-efficacy',\n",
    "    'Social',\n",
    "    'Subjective norms',\n",
    "    'Threat severity',\n",
    "    'Vulnerability'\n",
    "]\n",
    "\n",
    "flag_list = [\"com, noncom\"]\n",
    "\n",
    "output_folder = \"./templates\"\n",
    "os.makedirs(output_folder, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_response(a_model,a_prompt):\n",
    "    result = ollama.generate(model=a_model, prompt= a_prompt, stream=False)\n",
    "    while \"eval_duration\" not in result:\n",
    "        time.sleep(1)\n",
    "    return result\n",
    "\n",
    "def get_openai_response(a_prompt, multiplier):\n",
    "    responses = []\n",
    "    model = \"gpt-4o\"\n",
    "    for _ in range(multiplier):\n",
    "        response = openai_client.chat.completions.create(\n",
    "            model=model,\n",
    "            messages=[\n",
    "                {\"role\": \"system\", \"content\": \"You are a helpful assistant who follows instruction.\"},\n",
    "                {\"role\": \"user\", \"content\": a_prompt}\n",
    "            ]\n",
    "            )\n",
    "        responses.append(response.choices[0].message.content)\n",
    "    return responses"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "\n",
    "def combine_and_remove_duplicates(input_folder, output_file):\n",
    "    # List all CSV files in the input folder\n",
    "    csv_files = [file for file in os.listdir(input_folder) if file.endswith('.csv')]\n",
    "    \n",
    "    # Read all CSV files into separate DataFrames\n",
    "    dfs = [pd.read_csv(os.path.join(input_folder, file)) for file in csv_files]\n",
    "    \n",
    "    # Concatenate all DataFrames\n",
    "    combined_df = pd.concat(dfs, ignore_index=True)\n",
    "    \n",
    "    # Remove duplicates from the combined DataFrame\n",
    "    combined_df.drop_duplicates(inplace=True)\n",
    "    \n",
    "    # Write the combined DataFrame to a new CSV file\n",
    "    combined_df.to_csv(output_file, index=False)\n",
    "    print(f\"Combined CSV with duplicates removed saved to '{output_file}'\")\n",
    "\n",
    "def remove_non_charmap_characters(s):\n",
    "    \"\"\"Remove characters from the string s that cannot be encoded using the charmap codec.\"\"\"\n",
    "    return s.encode('charmap', 'ignore').decode('charmap')\n",
    "\n",
    "def remove_items_without_period(input_file, output_file):\n",
    "    with open(input_file, 'r', newline='') as infile:\n",
    "        with open(output_file, 'w', newline='') as outfile:\n",
    "            reader = csv.reader(infile)\n",
    "            writer = csv.writer(outfile)\n",
    "            for row in reader:\n",
    "                # Check if the last item in the row ends with a period\n",
    "                if row[-1].strip().endswith('.'):\n",
    "                    writer.writerow(row)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import prompt seeds\n",
    "promptseed_df = pd.read_csv('Cybonto-Gen1-PromptSeeds.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rate_per_minute = 500 #number of request per minute, must be divisible by 2\n",
    "# rate per minute is first dependent on your text generation endpoint constraint\n",
    "# rate per minute should be much smaller than batch size and be divisible by batch size\n",
    "batch_size = 3000 #number of one-sentence example for each construct-flag pair\n",
    "batch_num = int(batch_size/rate_per_minute)\n",
    "\n",
    "for flag in flag_list:\n",
    "    for construct in construct_list:\n",
    "        responses = []\n",
    "        # Filter the DataFrame based on the current construct and flag\n",
    "        filtered_rows = promptseed_df[(promptseed_df['Constructs'] == construct) & (promptseed_df['Flag'] == flag)]\n",
    "        \n",
    "        # Extract the 'Prompt' column values and extend the extracted_prompts list\n",
    "        extracted_prompts = filtered_rows['Prompt'].tolist()\n",
    "        for prompt in extracted_prompts:\n",
    "            for _ in range(batch_num): # loop through batches\n",
    "                batch_result1 = get_openai_response(prompt,int(rate_per_minute/2))\n",
    "                responses.extend(batch_result1)\n",
    "                time.sleep(30)\n",
    "                if len(batch_result1) > int(rate_per_minute/2)-3:\n",
    "                    batch_result2 = get_openai_response(prompt,int(rate_per_minute/2))\n",
    "                    responses.extend(batch_result2)\n",
    "                    time.sleep(30)\n",
    "        \n",
    "        file_name = f\"Ollagen_{construct}_{flag}.csv\"\n",
    "        output_path = os.path.join(output_folder, file_name)\n",
    "        with open(output_path, 'w') as file:\n",
    "            file.writelines([item + '\\n' for item in responses])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
